{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9526238088847134,
  "eval_steps": 500,
  "global_step": 22000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.06710508656556168,
      "grad_norm": 1.4924472570419312,
      "learning_rate": 9.776316378114795e-06,
      "loss": 0.986,
      "step": 500
    },
    {
      "epoch": 0.13421017313112335,
      "grad_norm": 1.2094018459320068,
      "learning_rate": 9.552632756229589e-06,
      "loss": 0.9811,
      "step": 1000
    },
    {
      "epoch": 0.201315259696685,
      "grad_norm": 1.5106759071350098,
      "learning_rate": 9.328949134344384e-06,
      "loss": 0.9871,
      "step": 1500
    },
    {
      "epoch": 0.2684203462622467,
      "grad_norm": 1.6820474863052368,
      "learning_rate": 9.105265512459178e-06,
      "loss": 0.9936,
      "step": 2000
    },
    {
      "epoch": 0.33552543282780833,
      "grad_norm": 1.3201414346694946,
      "learning_rate": 8.881581890573972e-06,
      "loss": 0.9812,
      "step": 2500
    },
    {
      "epoch": 0.40263051939337,
      "grad_norm": 1.4981727600097656,
      "learning_rate": 8.657898268688766e-06,
      "loss": 0.9741,
      "step": 3000
    },
    {
      "epoch": 0.4697356059589317,
      "grad_norm": 1.3862167596817017,
      "learning_rate": 8.434214646803562e-06,
      "loss": 0.9792,
      "step": 3500
    },
    {
      "epoch": 0.5368406925244934,
      "grad_norm": 1.274186134338379,
      "learning_rate": 8.210531024918356e-06,
      "loss": 0.9755,
      "step": 4000
    },
    {
      "epoch": 0.603945779090055,
      "grad_norm": 1.5283355712890625,
      "learning_rate": 7.986847403033152e-06,
      "loss": 0.983,
      "step": 4500
    },
    {
      "epoch": 0.6710508656556167,
      "grad_norm": 1.2278482913970947,
      "learning_rate": 7.763163781147946e-06,
      "loss": 0.9728,
      "step": 5000
    },
    {
      "epoch": 0.7381559522211784,
      "grad_norm": 1.4592698812484741,
      "learning_rate": 7.5394801592627396e-06,
      "loss": 0.977,
      "step": 5500
    },
    {
      "epoch": 0.80526103878674,
      "grad_norm": 1.637744426727295,
      "learning_rate": 7.315796537377534e-06,
      "loss": 0.9704,
      "step": 6000
    },
    {
      "epoch": 0.8723661253523017,
      "grad_norm": 1.482426643371582,
      "learning_rate": 7.092112915492328e-06,
      "loss": 0.975,
      "step": 6500
    },
    {
      "epoch": 0.9394712119178634,
      "grad_norm": 1.4508864879608154,
      "learning_rate": 6.868429293607123e-06,
      "loss": 0.9706,
      "step": 7000
    },
    {
      "epoch": 1.006576298483425,
      "grad_norm": 1.3517429828643799,
      "learning_rate": 6.644745671721917e-06,
      "loss": 0.9665,
      "step": 7500
    },
    {
      "epoch": 1.0736813850489868,
      "grad_norm": 1.4313188791275024,
      "learning_rate": 6.421062049836712e-06,
      "loss": 0.9485,
      "step": 8000
    },
    {
      "epoch": 1.1407864716145484,
      "grad_norm": 1.3280258178710938,
      "learning_rate": 6.197378427951506e-06,
      "loss": 0.9509,
      "step": 8500
    },
    {
      "epoch": 1.20789155818011,
      "grad_norm": 1.62037193775177,
      "learning_rate": 5.9736948060663e-06,
      "loss": 0.9466,
      "step": 9000
    },
    {
      "epoch": 1.2749966447456718,
      "grad_norm": 1.2136160135269165,
      "learning_rate": 5.750011184181095e-06,
      "loss": 0.9487,
      "step": 9500
    },
    {
      "epoch": 1.3421017313112333,
      "grad_norm": 1.5274674892425537,
      "learning_rate": 5.526327562295889e-06,
      "loss": 0.9424,
      "step": 10000
    },
    {
      "epoch": 1.4092068178767951,
      "grad_norm": 1.550378680229187,
      "learning_rate": 5.3026439404106835e-06,
      "loss": 0.9518,
      "step": 10500
    },
    {
      "epoch": 1.4763119044423567,
      "grad_norm": 1.3002405166625977,
      "learning_rate": 5.0789603185254775e-06,
      "loss": 0.9479,
      "step": 11000
    },
    {
      "epoch": 1.5434169910079185,
      "grad_norm": 1.376329779624939,
      "learning_rate": 4.855276696640272e-06,
      "loss": 0.943,
      "step": 11500
    },
    {
      "epoch": 1.61052207757348,
      "grad_norm": 1.3781367540359497,
      "learning_rate": 4.631593074755067e-06,
      "loss": 0.937,
      "step": 12000
    },
    {
      "epoch": 1.6776271641390417,
      "grad_norm": 1.4585076570510864,
      "learning_rate": 4.407909452869861e-06,
      "loss": 0.9378,
      "step": 12500
    },
    {
      "epoch": 1.7447322507046032,
      "grad_norm": 1.367462158203125,
      "learning_rate": 4.184225830984656e-06,
      "loss": 0.9388,
      "step": 13000
    },
    {
      "epoch": 1.811837337270165,
      "grad_norm": 1.4085041284561157,
      "learning_rate": 3.96054220909945e-06,
      "loss": 0.9399,
      "step": 13500
    },
    {
      "epoch": 1.8789424238357268,
      "grad_norm": 1.5391539335250854,
      "learning_rate": 3.7368585872142443e-06,
      "loss": 0.9329,
      "step": 14000
    },
    {
      "epoch": 1.9460475104012884,
      "grad_norm": 1.1983791589736938,
      "learning_rate": 3.5131749653290386e-06,
      "loss": 0.9411,
      "step": 14500
    },
    {
      "epoch": 2.01315259696685,
      "grad_norm": 1.327505350112915,
      "learning_rate": 3.2894913434438335e-06,
      "loss": 0.9314,
      "step": 15000
    },
    {
      "epoch": 2.0802576835324116,
      "grad_norm": 1.5425910949707031,
      "learning_rate": 3.065807721558628e-06,
      "loss": 0.9079,
      "step": 15500
    },
    {
      "epoch": 2.1473627700979736,
      "grad_norm": 1.4345545768737793,
      "learning_rate": 2.8421240996734223e-06,
      "loss": 0.9227,
      "step": 16000
    },
    {
      "epoch": 2.214467856663535,
      "grad_norm": 1.462062954902649,
      "learning_rate": 2.6184404777882166e-06,
      "loss": 0.9422,
      "step": 16500
    },
    {
      "epoch": 2.2815729432290968,
      "grad_norm": 1.4420387744903564,
      "learning_rate": 2.394756855903011e-06,
      "loss": 0.9336,
      "step": 17000
    },
    {
      "epoch": 2.3486780297946583,
      "grad_norm": 1.3587253093719482,
      "learning_rate": 2.1710732340178054e-06,
      "loss": 0.9461,
      "step": 17500
    },
    {
      "epoch": 2.41578311636022,
      "grad_norm": 1.55830979347229,
      "learning_rate": 1.9473896121326e-06,
      "loss": 0.9415,
      "step": 18000
    },
    {
      "epoch": 2.482888202925782,
      "grad_norm": 1.4573328495025635,
      "learning_rate": 1.7237059902473944e-06,
      "loss": 0.9418,
      "step": 18500
    },
    {
      "epoch": 2.5499932894913435,
      "grad_norm": 1.3665555715560913,
      "learning_rate": 1.5000223683621886e-06,
      "loss": 0.9406,
      "step": 19000
    },
    {
      "epoch": 2.617098376056905,
      "grad_norm": 1.6751980781555176,
      "learning_rate": 1.276338746476983e-06,
      "loss": 0.9396,
      "step": 19500
    },
    {
      "epoch": 2.6842034626224667,
      "grad_norm": 1.5091975927352905,
      "learning_rate": 1.0526551245917776e-06,
      "loss": 0.9379,
      "step": 20000
    },
    {
      "epoch": 2.7513085491880283,
      "grad_norm": 1.4462127685546875,
      "learning_rate": 8.289715027065719e-07,
      "loss": 0.9406,
      "step": 20500
    },
    {
      "epoch": 2.8184136357535903,
      "grad_norm": 1.312609314918518,
      "learning_rate": 6.052878808213663e-07,
      "loss": 0.9397,
      "step": 21000
    },
    {
      "epoch": 2.885518722319152,
      "grad_norm": 1.3873769044876099,
      "learning_rate": 3.8160425893616073e-07,
      "loss": 0.9419,
      "step": 21500
    },
    {
      "epoch": 2.9526238088847134,
      "grad_norm": 1.5177987813949585,
      "learning_rate": 1.5792063705095513e-07,
      "loss": 0.9358,
      "step": 22000
    }
  ],
  "logging_steps": 500,
  "max_steps": 22353,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1496326823936e+16,
  "train_batch_size": 2,
  "trial_name": null,
  "trial_params": null
}
