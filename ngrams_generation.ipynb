{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generación de texto con N-gramas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 1: Cargar el Archivo de Texto Limpio**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el texto limpio en una variable\n",
    "with open('corpus_argentina_limpio.txt', 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 2: Tokenización del Texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens con puntuación: ['mal', 'de', 'ninguno', 'sino', 'para', 'bien', 'de', 'todos', '.', 'fin']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Incluir signos de puntuación en la tokenización\n",
    "tokens = re.findall(r'\\b\\w+\\b|[.!?]', text.lower())\n",
    "print(\"Tokens con puntuación:\", tokens[-10:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 3: Construcción del Modelo de N-Gramas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "n = 2 \n",
    "\n",
    "# Crear el modelo de trigramas\n",
    "model = defaultdict(Counter)\n",
    "\n",
    "for i in range(len(tokens) - n + 1):\n",
    "    gram = tuple(tokens[i:i + n - 1])  # Dos primeras palabras como clave\n",
    "    next_word = tokens[i + n - 1]      # La tercera palabra es el objetivo\n",
    "    model[gram][next_word] += 1  # Incrementamos la cuenta para el siguiente token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 4: Generación de Texto Basado en el Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "la república argentina y ánimo de valdivia donde quiera reemplazarlo se sonaba en efecto dos años más vibrante y gobernados\n",
      "por amor con lentitud de a las pusimos en mira con esto y por su jornada llegamos al gobierno a\n",
      "su roce y que hacer público _es libre_ y su tiranía\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_text_with_end(model, starting_word, max_words=50):\n",
    "    # Inicia la lista con la palabra inicial\n",
    "    result = [starting_word]\n",
    "    for _ in range(max_words):\n",
    "        state = tuple(result[-1:])  # Última palabra como estado (bigramas)\n",
    "        if state in model and model[state]:\n",
    "            next_word = random.choices(\n",
    "                list(model[state].keys()), \n",
    "                weights=model[state].values()\n",
    "            )[0]\n",
    "            result.append(next_word)\n",
    "            # Finalizar si la palabra generada es un signo de puntuación\n",
    "            if next_word in ['.', '!', '?']:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(result)\n",
    "\n",
    "# Dividir el texto en fragmentos para impresión\n",
    "def print_in_chunks(text, chunk_size=20):\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        print(' '.join(words[i:i + chunk_size]))\n",
    "\n",
    "# Probar la generación con finalización automática\n",
    "starting_word = \"la\"  # Comenzar con una palabra en lugar de dos\n",
    "generated_text = generate_text_with_end(model, starting_word, 50)\n",
    "print(\"Texto generado:\")\n",
    "print_in_chunks(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trigramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "n = 3  # Cambia a trigramas\n",
    "\n",
    "# Crear el modelo de trigramas\n",
    "model = defaultdict(Counter)\n",
    "\n",
    "for i in range(len(tokens) - n + 1):\n",
    "    gram = tuple(tokens[i:i + n - 1])  # Dos primeras palabras como clave\n",
    "    next_word = tokens[i + n - 1]      # La tercera palabra es el objetivo\n",
    "    model[gram][next_word] += 1  # Incrementamos la cuenta para el siguiente token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 4: Generación de Texto Basado en el Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "la selección está jugando cada vez más añadió no sin echar una mirada de cariño duerme niño todavía no han\n",
      "pensado por eso los estafadores dignos de fama malogran un esfuerzo que le cuadre como lo dice muy contento .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_text_with_end(model, starting_words, max_words=50):\n",
    "    result = list(starting_words)\n",
    "    for _ in range(max_words):\n",
    "        state = tuple(result[-2:])  # Últimas dos palabras\n",
    "        if state in model and model[state]:\n",
    "            next_word = random.choices(list(model[state].keys()), weights=model[state].values())[0]\n",
    "            result.append(next_word)\n",
    "            # Finalizar si la palabra generada es un signo de puntuación\n",
    "            if next_word in ['.', '!', '?']:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(result)\n",
    "\n",
    "# Dividir el texto en fragmentos para impresión\n",
    "def print_in_chunks(text, chunk_size=20):\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        print(' '.join(words[i:i + chunk_size]))\n",
    "\n",
    "# Probar la generación con finalización automática\n",
    "starting_words = (\"la\", \"selección\")\n",
    "generated_text = generate_text_with_end(model, starting_words, 50)\n",
    "print(\"Texto generado:\")\n",
    "print_in_chunks( generated_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "n = 4 \n",
    "\n",
    "# Crear el modelo de trigramas\n",
    "model = defaultdict(Counter)\n",
    "\n",
    "for i in range(len(tokens) - n + 1):\n",
    "    gram = tuple(tokens[i:i + n - 1])  # Dos primeras palabras como clave\n",
    "    next_word = tokens[i + n - 1]      # La tercera palabra es el objetivo\n",
    "    model[gram][next_word] += 1  # Incrementamos la cuenta para el siguiente token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 4: Generación de Texto Basado en el Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "la argentina es la figura más americana que la revolución excepto en su símbolo exterior independencia del rey era agradable\n",
      "por cuanto era sustraerse a la autoridad que le dió un elixir que le hizo retroceder había dado contra la\n",
      "puerta pensando en lo loco que es el término que se les castigue\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_text_with_end(model, starting_words, max_words=50):\n",
    "    # Inicia la lista con las palabras iniciales\n",
    "    result = list(starting_words)\n",
    "    for _ in range(max_words):\n",
    "        state = tuple(result[-3:])  # Últimas tres palabras como estado (4-gramas)\n",
    "        if state in model and model[state]:\n",
    "            next_word = random.choices(\n",
    "                list(model[state].keys()), \n",
    "                weights=model[state].values()\n",
    "            )[0]\n",
    "            result.append(next_word)\n",
    "            # Finalizar si la palabra generada es un signo de puntuación\n",
    "            if next_word in ['.', '!', '?']:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(result)\n",
    "\n",
    "# Dividir el texto en fragmentos para impresión\n",
    "def print_in_chunks(text, chunk_size=20):\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        print(' '.join(words[i:i + chunk_size]))\n",
    "\n",
    "# Probar la generación con finalización automática\n",
    "starting_words = (\"la\", \"argentina\", \"es\")  # Tres palabras iniciales\n",
    "generated_text = generate_text_with_end(model, starting_words, 50)\n",
    "print(\"Texto generado:\")\n",
    "print_in_chunks(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5-gramas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "n = 5\n",
    "\n",
    "# Crear el modelo de trigramas\n",
    "model = defaultdict(Counter)\n",
    "\n",
    "for i in range(len(tokens) - n + 1):\n",
    "    gram = tuple(tokens[i:i + n - 1])  # Dos primeras palabras como clave\n",
    "    next_word = tokens[i + n - 1]      # La tercera palabra es el objetivo\n",
    "    model[gram][next_word] += 1  # Incrementamos la cuenta para el siguiente token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Paso 4: Generación de Texto Basado en el Modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado:\n",
      "en argentina llevamos el fútbol en la sangre y cada partido es como una nueva final del mundo .\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def generate_text_with_end(model, starting_words, max_words=50):\n",
    "    # Inicia la lista con las palabras iniciales\n",
    "    result = list(starting_words)\n",
    "    for _ in range(max_words):\n",
    "        state = tuple(result[-4:])  # Últimas cuatro palabras como estado (5-gramas)\n",
    "        if state in model and model[state]:\n",
    "            next_word = random.choices(\n",
    "                list(model[state].keys()), \n",
    "                weights=model[state].values()\n",
    "            )[0]\n",
    "            result.append(next_word)\n",
    "            # Finalizar si la palabra generada es un signo de puntuación\n",
    "            if next_word in ['.', '!', '?']:\n",
    "                break\n",
    "        else:\n",
    "            break\n",
    "    return ' '.join(result)\n",
    "\n",
    "# Dividir el texto en fragmentos para impresión\n",
    "def print_in_chunks(text, chunk_size=20):\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        print(' '.join(words[i:i + chunk_size]))\n",
    "\n",
    "# Probar la generación con finalización automática\n",
    "starting_words = (\"en\", \"argentina\", \"llevamos\", \"el\")  # Cuatro palabras iniciales\n",
    "generated_text = generate_text_with_end(model, starting_words, 50)\n",
    "print(\"Texto generado:\")\n",
    "print_in_chunks(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de los Textos Generados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Diversidad léxica**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texto generado\n",
      "la selección tus crímenes han sido abría a su hijo la partida de soldados sano . y en las leyes\n",
      "que rigen religiosas los casos en muy voluntario le aplican . les dijo don para el triunfo de ellas deben\n",
      "estar ciertas viene á apoyar los informado serále en otro mármol no puede todavia con trabajo á la de peligros\n",
      "y emociones habia . quien duda revelar las debilidades de invitado inmediatamente a jugar los llantos de la la biblioteca\n",
      "nacional de sanchez y el capitán de córdoba . la pensamiento secreto de quiroga río cuarto . si tierra esté\n",
      "\n",
      "Diversidad léxica: 0.74 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def lexical_diversity(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words) / len(words)\n",
    "\n",
    "def generate_text_fixed_length(model, starting_words, num_words=50):\n",
    "    result = list(starting_words)\n",
    "    for _ in range(num_words - len(starting_words)):  # Ajustamos para alcanzar exactamente `num_words`\n",
    "        state = tuple(result[-2:])  # Últimas dos palabras\n",
    "        if state in model and model[state]:\n",
    "            # Elegir la siguiente palabra basada en las probabilidades del modelo\n",
    "            next_word = random.choices(list(model[state].keys()), weights=model[state].values())[0]\n",
    "            result.append(next_word)\n",
    "        else:\n",
    "            # Si no hay más opciones, reiniciar con un nuevo estado aleatorio\n",
    "            state = random.choice(list(model.keys()))\n",
    "            result.extend(state)\n",
    "    return ' '.join(result[:num_words])  # Limitar la salida exactamente a `num_words`\n",
    "\n",
    "# Dividir el texto en fragmentos para impresión\n",
    "def print_in_chunks(text, chunk_size=20):\n",
    "    words = text.split()\n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        print(' '.join(words[i:i + chunk_size]))\n",
    "\n",
    "\n",
    "\n",
    "# Generar texto de muestra y calcular la diversidad léxica (español)\n",
    "starting_words = (\"la\", \"selección\")\n",
    "sample_text = generate_text_fixed_length(model, starting_words, 100)  # Genera exactamente 100 palabras\n",
    "diversity = lexical_diversity(sample_text)\n",
    "\n",
    "print(\"Texto generado\")\n",
    "print_in_chunks(sample_text)\n",
    "print(\"\\nDiversidad léxica:\", diversity, \"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Longitud promedio de las oraciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longitud promedio de las oraciones: 13.428571428571429\n"
     ]
    }
   ],
   "source": [
    "def average_sentence_length(text):\n",
    "    sentences = text.split('.')\n",
    "    return sum(len(sentence.split()) for sentence in sentences) / len(sentences)\n",
    "\n",
    "# Calcular la longitud promedio de las oraciones (español)\n",
    "avg_sentence_length_es = average_sentence_length(sample_text)\n",
    "print(\"Longitud promedio de las oraciones:\", avg_sentence_length_es)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ratio de Repetición**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratio de repetición: 0.13\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def repetition_ratio(text):\n",
    "    words = text.split()\n",
    "    word_counts = Counter(words)\n",
    "    repeated_words = sum(1 for count in word_counts.values() if count > 1)\n",
    "    return repeated_words / len(words)\n",
    "\n",
    "# Ratio de repetición para el texto \n",
    "repetition = repetition_ratio(sample_text)\n",
    "print(\"Ratio de repetición:\", repetition)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cantidad de Palabras Únicas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de palabras únicas: 71\n"
     ]
    }
   ],
   "source": [
    "def unique_words_count(text):\n",
    "    words = text.split()\n",
    "    unique_words = set(words)\n",
    "    return len(unique_words)\n",
    "\n",
    "# Cantidad de palabras únicas en español e inglés\n",
    "unique_words = unique_words_count(sample_text)\n",
    "print(\"Cantidad de palabras únicas:\", unique_words)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cell_detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
